# PostgreSQL + Redis Observer Configuration
# ============================================
#
# This deployment adds Redis for performance optimization:
# - PostgreSQL LISTEN/NOTIFY for event sourcing
# - Redis for deduplication (at-least-once delivery guarantee)
# - Redis for action result caching (100x faster for repeated actions)
#
# Best for:
# - Single PostgreSQL database
# - Medium event volume (1000-10000 events/sec)
# - Needs reliability (deduplication) and performance (caching)
# - Can run Redis instance

# Example observer 1: Webhook on order creation
[[observers]]
entity = "Order"
event_type = "INSERT"

[[observers.actions]]
body_template = '''
{
  "order_id": "{{ data.id }}",
  "total": {{ data.total }},
  "customer_id": "{{ data.customer_id }}"
}
'''
type = "webhook"
url = "https://analytics.example.com/orders"

[observers.retry]
backoff_strategy = "exponential"
initial_delay_ms = 100
max_attempts = 3
max_delay_ms = 30000

# Example observer 3: Slack notification for high-value orders
[[observers]]
condition = "data.status == 'shipped'"
entity = "Order"
event_type = "UPDATE"

[[observers.actions]]
body_template = "Order #{{ data.id }} is on its way. Tracking: {{ data.tracking_number }}"
subject = "Your order has shipped!"
to_template = "{{ data.customer_email }}"
type = "email"

[observers.retry]
initial_delay_ms = 200
max_attempts = 3
max_delay_ms = 30000

[[observers]]
condition = "data.total > 1000"
entity = "Order"
event_type = "INSERT"

[[observers.actions]]
message_template = "ðŸŽ‰ High-value order! ${{ data.total }} from {{ data.customer_email }}"
type = "slack"
webhook_url_env = "SLACK_WEBHOOK_URL"

# Performance features (Redis-backed)
[performance]
backlog_alert_threshold = 500
# Runtime settings
channel_capacity = 1000
concurrent_timeout_ms = 30000
enable_caching = true  # âœ… Action result caching (100x faster cache hits)
enable_concurrent = true  # âœ… Concurrent action execution
enable_dedup = true  # âœ… Event deduplication (prevents duplicate processing)
max_concurrency = 50
max_concurrent_actions = 10
overflow_policy = "drop"
shutdown_timeout = "30s"

# Redis configuration (dedup + caching)
[redis]
cache_ttl_secs = 60  # 1 minute cache TTL
command_timeout_secs = 2
connect_timeout_secs = 5
dedup_window_secs = 300  # 5 minutes dedup window
pool_size = 10
url = "redis://localhost:6379"

# Transport configuration
[transport]
run_bridge = false
run_executors = true
transport = "postgres"
