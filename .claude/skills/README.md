# FraiseQL Code Review Resources

Comprehensive, independent code review prompts and questions for FraiseQL v1.9.1.

## ğŸ“š What's Included

### 1. **code-review-prompt.md** (230 lines)
The master review prompt - a production-grade code review specification.

**Use this when**: You want a comprehensive, professional-grade review of the entire codebase.

**Covers**:
- âœ… Architecture & Design (20%)
- âœ… Security (25%)
- âœ… Performance & Optimization (20%)
- âœ… Reliability & Error Handling (15%)
- âœ… Code Quality & Maintainability (10%)
- âœ… Operational Readiness (10%)

**Time**: 15 minutes | **Quality**: â­â­â­â­â­ | **Output**: 15-25 page report

---

### 2. **code-review-usage.md** (219 lines)
How to run the review and what to expect.

**Includes**:
- Three different review approaches (web/local/quick)
- Expected output structure
- Tips for best results
- Key file priorities
- Next steps after review

**Start here to understand**: How to submit the review and what to expect.

---

### 3. **targeted-review-questions.md** (243 lines)
50+ specific technical questions organized by topic.

**Use this when**: You want to focus on specific areas or verify particular concerns.

**Includes**:
- **Security Questions** (30+): Auth, RBAC, GraphQL, DoS, data protection
- **Performance Questions** (20+): N+1 queries, caching, subscriptions, memory
- **Architecture Questions** (10+): Design, scalability, operational
- **Testing & Reliability** (15+): Coverage, error handling, failure modes
- **Vulnerability Checks**: Code examples to test specific risks
- **Checklist**: 15-point production readiness checklist

**Time**: 10 minutes | **Quality**: â­â­â­â­â­ | **Output**: 5-10 page focused analysis

---

## ğŸš€ Quick Start

### For Comprehensive Review
1. Open `code-review-prompt.md`
2. Read `code-review-usage.md` â†’ "Option 1: Web Chat"
3. Copy entire prompt and paste into Claude
4. Wait 10-15 minutes for full report

### For Quick Assessment
1. Read `code-review-usage.md` â†’ "Option 3: Streamlined Quick Review"
2. Use the simplified prompt from that section
3. Takes 5-10 minutes

### For Specific Concerns
1. Open `targeted-review-questions.md`
2. Find the relevant section (security/performance/architecture)
3. Ask Claude those specific questions
4. Get focused analysis in 10 minutes

---

## ğŸ“Š Coverage Matrix

| Area | Prompt | Questions | Usage |
|------|--------|-----------|-------|
| Security | âœ… (25%) | âœ… (30+) | Focus here first |
| Performance | âœ… (20%) | âœ… (20+) | Critical for scale |
| Architecture | âœ… (20%) | âœ… (10+) | Long-term concerns |
| Reliability | âœ… (15%) | âœ… (15+) | Production ops |
| Code Quality | âœ… (10%) | âœ… (Tools) | Already verified |
| Operations | âœ… (10%) | âœ… (5+) | Deployment needs |

---

## âœ… What We Already Know

The FraiseQL codebase has been verified to:
- âœ… Pass clippy pedantic (0 warnings across 161 files)
- âœ… Compile successfully in strict mode (-D warnings)
- âœ… Build for production (release profile)
- âœ… Follow Rust idioms and best practices
- âœ… Have complete error documentation

**This review will assess**:
- Security & authorization
- Performance under load
- Scalability & architecture
- Operational readiness
- Production suitability

---

## ğŸ“– How to Use Each File

### code-review-prompt.md

**Best for**: Comprehensive, executive-level assessment

**How to use**:
```
1. Open the file
2. Copy ALL content
3. Go to https://claude.ai
4. Create new conversation
5. Paste entire prompt
6. Wait for report
```

**Expected output**:
- Executive summary
- Critical issues (must fix)
- Major issues (should fix)
- Minor improvements
- Risk assessment matrix
- Component-by-component analysis

**Length**: 15-25 pages

---

### code-review-usage.md

**Best for**: Understanding how to run a review

**How to use**:
```
1. Read the "Quick Start" section
2. Choose your approach (web/local/quick)
3. Follow the specific instructions
4. Submit prompt to Claude
5. Review findings
```

**Includes**:
- 3 different review approaches with tradeoffs
- Expected output format
- Tips for best results
- File organization and priorities
- Timeline expectations
- Next steps

---

### targeted-review-questions.md

**Best for**: Deep-dive on specific areas

**How to use**:
```
1. Identify area of concern (security/performance/architecture)
2. Open the corresponding section
3. Copy relevant questions
4. Ask Claude those specific questions
5. Get focused analysis
```

**Sections**:
- ğŸ”’ Security (Auth, RBAC, GraphQL, DoS, data protection)
- âš¡ Performance (N+1, caching, subscriptions, memory)
- ğŸ—ï¸ Architecture (Design, scalability, operations)
- ğŸ§ª Testing (Coverage, error handling, reliability)
- ğŸ“‹ Checklist (15-point production readiness)

---

## ğŸ¯ Review Priorities

**Highest Priority** (Review first):
1. Security - Can RBAC be bypassed? Is multi-tenancy isolated?
2. Data Loss - Are transactions atomic? Can data be lost?
3. Performance - Will subscriptions scale? N+1 queries?

**High Priority** (Review second):
1. Architecture - Can design scale? What breaks first under load?
2. Operational - Can it run in production? Monitoring? Recovery?
3. Reliability - How does it fail? Can it recover?

**Medium Priority** (Review third):
1. Code quality - Maintainability, documentation, testing
2. Integration - How does Python/Rust boundary work?
3. Extensibility - Can it be extended? Changed?

---

## ğŸ“Š Expected Findings

**Common findings in production code reviews**:
- Security: 3-5 findings (mix of critical and minor)
- Performance: 2-4 findings (optimization opportunities)
- Architecture: 1-3 findings (scalability concerns)
- Operational: 1-2 findings (monitoring/recovery)
- Code quality: 0-5 findings (minor improvements)

**Total expected**: 7-19 findings, mostly actionable improvements

---

## ğŸ”„ Review Workflow

```
1. Submit Prompt
   â”œâ”€ Choose approach (web/local/quick)
   â””â”€ Paste prompt to Claude

2. Receive Report
   â”œâ”€ Save markdown output
   â””â”€ Review findings (30 min)

3. Analyze
   â”œâ”€ Separate critical/major/minor
   â”œâ”€ Estimate effort
   â””â”€ Prioritize work

4. Plan Work
   â”œâ”€ Create GitHub issues
   â”œâ”€ Schedule in sprints
   â””â”€ Assign owners

5. Verify Fixes
   â”œâ”€ Re-run focused reviews
   â”œâ”€ Confirm issues resolved
   â””â”€ Document decisions
```

---

## â“ FAQ

**Q: How long does a review take?**
A: 10-15 minutes to get the report, then 30 min to 1 hour to analyze and plan.

**Q: Which approach should I use?**
A: Start with "Option 1: Web Chat" for comprehensive review. Use targeted questions for specific concerns.

**Q: Will it find security issues?**
A: Yes. The prompts are designed to uncover security vulnerabilities, data loss risks, and architectural problems.

**Q: Can I use the same prompt twice?**
A: Yes. After fixing issues, submit the same prompt to verify improvements.

**Q: What if we disagree with a finding?**
A: Document why you're not fixing it. Create an ADR (Architecture Decision Record) with the rationale.

**Q: How often should we review?**
A: After major architectural changes or before production release. Also after security patches.

---

## ğŸ“ File Locations

```
.claude/skills/
â”œâ”€â”€ README.md                      â† This file
â”œâ”€â”€ code-review-prompt.md          â† Main review prompt (230 lines)
â”œâ”€â”€ code-review-usage.md           â† How to run reviews (219 lines)
â””â”€â”€ targeted-review-questions.md   â† Specific technical questions (243 lines)

Repository: /home/lionel/code/fraiseql
```

---

## ğŸ“ Learning Resource

These prompts are also useful for:
- Learning what production-grade code reviews look like
- Understanding what reviewers look for in code
- Building a checklist for your own code reviews
- Training junior developers on review standards

---

## ğŸ“ Support

**Need help using these resources?**
1. Read `code-review-usage.md` for instructions
2. Check `targeted-review-questions.md` for similar questions
3. Ask Claude for clarification on specific findings

**Want to improve the prompts?**
1. Note what was missing from the review
2. Add those questions to a follow-up
3. Update the prompt files with new insights

---

## ğŸ† Best Practices

1. **Review Timing**: Run before production release
2. **Save Reports**: Keep all review reports for historical reference
3. **Track Changes**: Link GitHub issues to review findings
4. **Follow-Up**: Re-run review after major fixes
5. **Documentation**: Document why you accept/reject findings

---

## ğŸ“Š Metrics

**Files**: 3 markdown files, 692 lines total
**Coverage**: Architecture, Security, Performance, Reliability, Quality, Operations
**Questions**: 50+ specific technical questions
**Time Investment**: 15-20 minutes for comprehensive review

---

**Version**: 1.0
**Created**: 2026-01-04
**For**: FraiseQL v1.9.1
**Status**: Ready for independent review

---

## Ready to Review?

Choose your approach and get started:

1. **Professional Review** (15 min) â†’ Use `code-review-prompt.md`
2. **Quick Assessment** (5 min) â†’ Use simplified prompt from `code-review-usage.md`
3. **Focused Deep-Dive** (10 min) â†’ Use `targeted-review-questions.md`

ğŸ‘‰ **Next Step**: Open the file that matches your chosen approach!
