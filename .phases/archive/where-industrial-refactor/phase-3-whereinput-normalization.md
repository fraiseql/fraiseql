# Phase 3: Implement WhereInput Normalization [GREEN]

## Objective

Implement normalization logic to convert WhereInput objects to canonical `WhereClause` representation. This completes the normalization layer and fixes the current bug.

## Context

Phase 2 implemented dict normalization. Now we handle WhereInput objects, which are the primary API for GraphQL resolvers.

WhereInput objects are generated by `create_graphql_where_input()` and contain:
- Nested WhereInput objects for relationships
- Filter objects (UUIDFilter, StringFilter, etc.) for operators
- Logical operators (OR, AND, NOT)

The current bug exists because `_where_obj_to_dict()` doesn't properly extract Filter objects, causing FK detection to fail.

## Files to Modify

- `src/fraiseql/sql/graphql_where_generator.py` - Add `_to_whereinput_dict()` to generated classes
- `src/fraiseql/where_normalization.py` - Add `normalize_whereinput()` function
- `src/fraiseql/db.py` - Call `normalize_whereinput()` in `_normalize_where()`
- `tests/unit/test_where_normalization.py` - Un-skip WhereInput tests
- `tests/regression/test_nested_filter_id_field.py` - Add SQL equivalence tests

## Implementation Steps

### Step 1: Add Conversion Method to Generated WhereInput Classes

Modify `src/fraiseql/sql/graphql_where_generator.py`:

```python
def create_graphql_where_input(cls: type, name: str | None = None) -> type:
    """Create a GraphQL-compatible where input type with operator filters."""

    # ... existing field generation code ...

    # Add conversion method to class
    def _to_whereinput_dict(self) -> dict[str, Any]:
        """Convert WhereInput to normalized dict format.

        This method recursively extracts all filter values from the WhereInput
        object and its nested objects/filters, converting them to a plain dict
        structure that can be normalized to WhereClause.

        Returns:
            Dict representation with filter operators extracted

        Examples:
            # WhereInput with UUIDFilter
            AllocationWhereInput(
                machine=MachineWhereInput(
                    id=UUIDFilter(eq=UUID("123"))
                )
            )._to_whereinput_dict()

            # Returns:
            {
                "machine": {
                    "id": {
                        "eq": UUID("123")
                    }
                }
            }
        """
        result = {}

        for field_name, field_value in self.__dict__.items():
            # Skip None values and private fields
            if field_value is None or field_name.startswith("_"):
                continue

            # Handle logical operators (OR, AND, NOT)
            if field_name in ("OR", "AND", "NOT"):
                if field_name in ("OR", "AND") and isinstance(field_value, list):
                    # OR/AND: list of WhereInput objects
                    result[field_name] = [
                        item._to_whereinput_dict() if hasattr(item, "_to_whereinput_dict") else item
                        for item in field_value
                    ]
                elif field_name == "NOT" and hasattr(field_value, "_to_whereinput_dict"):
                    # NOT: single WhereInput object
                    result[field_name] = field_value._to_whereinput_dict()
                else:
                    result[field_name] = field_value
                continue

            # Handle nested WhereInput objects
            if hasattr(field_value, "_to_whereinput_dict"):
                nested_dict = field_value._to_whereinput_dict()
                if nested_dict:
                    result[field_name] = nested_dict
            # Handle Filter objects (UUIDFilter, StringFilter, etc.)
            elif hasattr(field_value, "__dict__") and _is_filter_object(field_value):
                # Extract non-None operators from filter
                filter_dict = {
                    op: val
                    for op, val in field_value.__dict__.items()
                    if val is not None and not op.startswith("_")
                }
                if filter_dict:
                    result[field_name] = filter_dict
            # Handle plain dicts
            elif isinstance(field_value, dict):
                result[field_name] = field_value
            # Handle scalar values
            elif isinstance(field_value, (str, int, float, bool, uuid.UUID, date, datetime)):
                result[field_name] = {"eq": field_value}

        return result

    def _is_filter_object(obj: Any) -> bool:
        """Check if object is a Filter type (has operator fields)."""
        if not hasattr(obj, "__dict__"):
            return False

        # Filter objects have operator fields
        operator_fields = {"eq", "neq", "in_", "nin", "gt", "gte", "lt", "lte",
                          "contains", "icontains", "startswith", "endswith",
                          "istartswith", "iendswith", "isnull"}
        obj_fields = set(obj.__dict__.keys())

        # If it has at least one operator field, it's a Filter
        return bool(operator_fields & obj_fields)

    # Attach method to class
    WhereInputClass._to_whereinput_dict = _to_whereinput_dict

    # ... rest of existing code ...

    return WhereInputClass
```

### Step 2: Add WhereInput Normalization Function

Add to `src/fraiseql/where_normalization.py`:

```python
def normalize_whereinput(
    where_input: Any,
    view_name: str,
    table_columns: set[str] | None = None,
    jsonb_column: str = "data",
) -> WhereClause:
    """Normalize WhereInput object to canonical WhereClause.

    Args:
        where_input: WhereInput object with _to_whereinput_dict() method
        view_name: Table/view name for metadata lookup
        table_columns: Set of actual table column names
        jsonb_column: JSONB column name (default: "data")

    Returns:
        Canonical WhereClause representation

    Raises:
        TypeError: If where_input doesn't have _to_whereinput_dict() method
    """
    if not hasattr(where_input, "_to_whereinput_dict"):
        raise TypeError(
            f"WhereInput object must have _to_whereinput_dict() method. "
            f"Got: {type(where_input)}"
        )

    # Convert to dict
    where_dict = where_input._to_whereinput_dict()

    logger.debug(
        f"WhereInput normalization: converted to dict",
        extra={
            "input_type": type(where_input).__name__,
            "dict_keys": list(where_dict.keys()),
        }
    )

    # Use dict normalization logic
    return normalize_dict_where(where_dict, view_name, table_columns, jsonb_column)
```

### Step 3: Update _normalize_where() to Handle WhereInput

Modify `src/fraiseql/db.py`:

```python
from fraiseql.where_normalization import normalize_dict_where, normalize_whereinput

class FraiseQLRepository:
    # ... existing code ...

    def _normalize_where(
        self,
        where: dict | Any,
        view_name: str,
        table_columns: set[str] | None = None,
    ) -> WhereClause:
        """Normalize WHERE clause to canonical WhereClause representation."""

        # Already normalized
        if isinstance(where, WhereClause):
            return where

        # Dict-based WHERE
        if isinstance(where, dict):
            jsonb_column = "data"
            if view_name in _table_metadata:
                metadata = _table_metadata[view_name]
                if metadata.get("has_jsonb_data", False):
                    jsonb_column = metadata.get("jsonb_column", "data")

            return normalize_dict_where(
                where, view_name, table_columns, jsonb_column
            )

        # WhereInput-based WHERE
        if hasattr(where, "_to_whereinput_dict"):
            jsonb_column = "data"
            if view_name in _table_metadata:
                metadata = _table_metadata[view_name]
                if metadata.get("has_jsonb_data", False):
                    jsonb_column = metadata.get("jsonb_column", "data")

            return normalize_whereinput(
                where, view_name, table_columns, jsonb_column
            )

        raise TypeError(
            f"Unsupported WHERE type: {type(where)}. "
            f"Expected dict or WhereInput object."
        )
```

### Step 4: Enable WhereInput Tests

Modify `tests/unit/test_where_normalization.py`:

```python
# Un-skip WhereInput normalization tests
class TestWhereInputNormalization:
    """Test WhereInput normalization."""

    def test_normalize_whereinput_with_uuid_filter(self):
        """Test normalizing WhereInput with UUIDFilter."""
        # ... test code (remove @pytest.mark.skip) ...

    # Add more tests ...


class TestNormalizationEquivalence:
    """Test dict and WhereInput produce identical WhereClause."""

    def test_dict_and_whereinput_produce_identical_whereclause(self):
        """Test dict and WhereInput normalize to identical WhereClause."""
        # ... test code (remove @pytest.mark.skip) ...
```

### Step 5: Add SQL Equivalence Tests to Regression Suite

Add to `tests/regression/test_nested_filter_id_field.py`:

```python
async def test_whereinput_nested_filter_generates_fk_sql(
    class_db_pool, setup_hybrid_table, caplog
):
    """Verify WhereInput nested filters generate FK SQL, not JSONB SQL."""
    test_data = setup_hybrid_table

    register_type_for_view(
        "tv_allocation",
        Allocation,
        table_columns={"id", "machine_id", "device_id", "status", "tenant_id", "created_at", "data"},
        has_jsonb_data=True,
    )

    repo = FraiseQLRepository(class_db_pool, context={"tenant_id": "test"})

    MachineWhereInput = create_graphql_where_input(Machine)
    AllocationWhereInput = create_graphql_where_input(Allocation)

    where_input = AllocationWhereInput(
        machine=MachineWhereInput(id=UUIDFilter(eq=test_data["machine2_id"]))
    )

    # Capture debug logs to verify FK detection
    with caplog.at_level(logging.DEBUG):
        result = await repo.find("tv_allocation", where=where_input)

    # Should see FK detection log
    fk_logs = [r for r in caplog.records if "FK nested object filter" in r.message or "FK nested filter" in r.message]
    assert len(fk_logs) > 0, "Should detect FK column for machine.id filter"

    # Should NOT see operator strategy failure warning
    warnings = [r for r in caplog.records if "Operator strategy failed" in r.message]
    assert len(warnings) == 0, f"Should not fail with operator warning: {warnings}"

    # Should NOT see "Unsupported operator: id" warning
    unsupported_logs = [r for r in caplog.records if "Unsupported operator: id" in r.message]
    assert len(unsupported_logs) == 0, "Should not try to use JSONB path for id field"

    # Verify correct results
    results = extract_graphql_data(result, "tv_allocation")
    assert len(results) == test_data["machine2_count"]


async def test_dict_and_whereinput_generate_identical_sql(
    class_db_pool, setup_hybrid_table
):
    """Verify dict and WhereInput generate identical SQL queries."""
    test_data = setup_hybrid_table

    register_type_for_view(
        "tv_allocation",
        Allocation,
        table_columns={"id", "machine_id", "device_id", "status", "tenant_id", "created_at", "data"},
        has_jsonb_data=True,
    )

    repo = FraiseQLRepository(class_db_pool, context={"tenant_id": "test"})

    # Normalize both inputs
    where_dict = {"machine": {"id": {"eq": test_data["machine2_id"]}}}

    MachineWhereInput = create_graphql_where_input(Machine)
    AllocationWhereInput = create_graphql_where_input(Allocation)
    where_input = AllocationWhereInput(
        machine=MachineWhereInput(id=UUIDFilter(eq=test_data["machine2_id"]))
    )

    # Get table columns
    table_columns = {"id", "machine_id", "device_id", "status", "tenant_id", "created_at", "data"}

    # Normalize both
    clause_dict = repo._normalize_where(where_dict, "tv_allocation", table_columns)
    clause_input = repo._normalize_where(where_input, "tv_allocation", table_columns)

    # Should produce identical WhereClause
    assert len(clause_dict.conditions) == len(clause_input.conditions)
    assert clause_dict.conditions[0].field_path == clause_input.conditions[0].field_path
    assert clause_dict.conditions[0].operator == clause_input.conditions[0].operator
    assert clause_dict.conditions[0].value == clause_input.conditions[0].value
    assert clause_dict.conditions[0].lookup_strategy == clause_input.conditions[0].lookup_strategy
    assert clause_dict.conditions[0].target_column == clause_input.conditions[0].target_column

    # Generate SQL from both
    sql_dict, params_dict = clause_dict.to_sql()
    sql_input, params_input = clause_input.to_sql()

    # SQL should be identical
    assert sql_dict.as_string(None) == sql_input.as_string(None)
    assert params_dict == params_input

    # SQL should use FK column, not JSONB path
    sql_str = sql_dict.as_string(None)
    assert "machine_id" in sql_str
    assert "data->'machine'" not in sql_str
```

### Step 6: Add More WhereInput Tests

Add to `tests/unit/test_where_normalization.py`:

```python
class TestWhereInputNormalization:
    # ... existing tests ...

    def test_normalize_whereinput_with_string_filter(self):
        """Test normalizing WhereInput with StringFilter."""
        from fraiseql.sql import StringFilter, create_graphql_where_input
        from tests.regression.test_nested_filter_id_field import Allocation

        AllocationWhereInput = create_graphql_where_input(Allocation)

        where_input = AllocationWhereInput(
            status=StringFilter(eq="active")
        )

        repo = FraiseQLRepository(None)
        clause = repo._normalize_where(
            where_input,
            view_name="tv_allocation",
            table_columns={"status", "data"}
        )

        assert len(clause.conditions) == 1
        assert clause.conditions[0].operator == "eq"
        assert clause.conditions[0].value == "active"

    def test_normalize_whereinput_with_multiple_filters(self):
        """Test normalizing WhereInput with multiple fields."""
        from fraiseql.sql import StringFilter, UUIDFilter, create_graphql_where_input
        from tests.regression.test_nested_filter_id_field import Allocation, Machine

        MachineWhereInput = create_graphql_where_input(Machine)
        AllocationWhereInput = create_graphql_where_input(Allocation)

        machine_id = uuid.UUID("12345678-1234-1234-1234-123456789abc")
        where_input = AllocationWhereInput(
            status=StringFilter(eq="active"),
            machine=MachineWhereInput(id=UUIDFilter(eq=machine_id))
        )

        repo = FraiseQLRepository(None)
        clause = repo._normalize_where(
            where_input,
            view_name="tv_allocation",
            table_columns={"status", "machine_id", "data"}
        )

        assert len(clause.conditions) == 2

    def test_normalize_whereinput_with_or_operator(self):
        """Test normalizing WhereInput with OR operator."""
        from fraiseql.sql import StringFilter, create_graphql_where_input
        from tests.regression.test_nested_filter_id_field import Allocation

        AllocationWhereInput = create_graphql_where_input(Allocation)

        where_input = AllocationWhereInput(
            OR=[
                AllocationWhereInput(status=StringFilter(eq="active")),
                AllocationWhereInput(status=StringFilter(eq="pending"))
            ]
        )

        repo = FraiseQLRepository(None)
        clause = repo._normalize_where(
            where_input,
            view_name="tv_allocation",
            table_columns={"status"}
        )

        assert len(clause.nested_clauses) == 1
        assert clause.nested_clauses[0].logical_op == "OR"
```

## Verification Commands

```bash
# Run WhereInput normalization tests
uv run pytest tests/unit/test_where_normalization.py::TestWhereInputNormalization -v

# Run equivalence tests
uv run pytest tests/unit/test_where_normalization.py::TestNormalizationEquivalence -v

# Run regression tests with logging
uv run pytest tests/regression/test_nested_filter_id_field.py::test_whereinput_nested_filter_generates_fk_sql -v -s

# Run SQL equivalence test
uv run pytest tests/regression/test_nested_filter_id_field.py::test_dict_and_whereinput_generate_identical_sql -v

# Verify the bug is fixed
uv run pytest tests/regression/test_nested_filter_id_field.py::test_whereinput_and_dict_produce_same_results -v

# Run all WHERE tests
uv run pytest tests/unit/test_where_clause.py tests/unit/test_where_normalization.py tests/regression/test_nested_filter_id_field.py -v

# Full test suite
uv run pytest tests/ -v
```

## Acceptance Criteria

- [ ] `_to_whereinput_dict()` method added to generated WhereInput classes
- [ ] Method correctly extracts Filter objects (UUIDFilter, StringFilter, etc.)
- [ ] Method handles nested WhereInput objects recursively
- [ ] `normalize_whereinput()` function implemented
- [ ] All WhereInput normalization tests pass
- [ ] Dict and WhereInput produce identical `WhereClause` (equivalence tests pass)
- [ ] Dict and WhereInput produce identical SQL (SQL equivalence tests pass)
- [ ] **Original bug is fixed**: WhereInput nested filters use FK column
- [ ] No "Unsupported operator: id" warnings for valid queries
- [ ] FK detection logs show correct behavior
- [ ] All existing regression tests pass
- [ ] Code coverage >85% for new code

## DO NOT

- ❌ Modify SQL generation yet (that's Phase 4)
- ❌ Remove old `_where_obj_to_dict()` yet (keep until Phase 6)
- ❌ Change `_build_where_clause()` to use normalization yet

## Notes

This phase **fixes the current bug** by implementing proper WhereInput → dict conversion.

The key insight: Instead of trying to convert `SQL WHERE objects → dict`, we convert `WhereInput → dict` BEFORE converting to SQL. This preserves all type information.

After this phase, normalization is complete for both dict and WhereInput inputs.

## Next Phase

**Phase 4:** Refactor SQL generation to use `WhereClause` directly, eliminating the old code paths.
