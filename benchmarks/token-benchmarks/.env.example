# LLM Token Test Suite Configuration
# Copy this file to .env and fill in your API keys

# ====================
# LLM Provider Settings
# ====================

# OpenAI Configuration
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4  # Options: gpt-4, gpt-4-turbo, gpt-3.5-turbo
OPENAI_TEMPERATURE=0.2  # Lower = more deterministic (0.0-1.0)

# Anthropic Configuration
# Get your API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-...
ANTHROPIC_MODEL=claude-3-opus-20240229  # Options: claude-3-opus, claude-3-sonnet, claude-3-haiku
ANTHROPIC_TEMPERATURE=0.2

# Hugging Face / Local Models
# For local models, no API key needed
HF_MODEL=codellama/CodeLlama-7b-Python-hf
HF_DEVICE=cpu  # Options: cpu, cuda, mps (for M1/M2 Macs)

# ====================
# Test Configuration
# ====================

# Maximum tokens to generate per request
MAX_TOKENS=4000

# Timeout for API calls (in seconds)
TIMEOUT_SECONDS=60

# Number of retries for failed API calls
RETRY_COUNT=3

# Run tests in parallel (requires more API rate limit)
PARALLEL_TESTS=False

# ====================
# Output Configuration
# ====================

# Save all generated code to files for inspection
SAVE_GENERATED_CODE=True

# Generate visualization charts (requires matplotlib)
GENERATE_VISUALIZATIONS=True

# Report format: json, html, markdown
REPORT_FORMAT=json

# ====================
# Cost Tracking
# ====================

# Enable cost tracking and warnings
TRACK_COSTS=True

# Maximum cost per test run (USD) - warns if exceeded
MAX_COST_PER_RUN=10.0

# ====================
# Database Configuration (Optional)
# ====================

# For validating generated SQL/database code
DATABASE_URL=postgresql://user:password@localhost:5432/test_db

# ====================
# Advanced Settings
# ====================

# Cache generated responses to avoid repeated API calls
ENABLE_CACHE=True
CACHE_DIR=benchmarks/.cache

# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# Save detailed API logs
SAVE_API_LOGS=False

# Custom prompts directory (for testing variations)
CUSTOM_PROMPTS_DIR=benchmarks/prompts

# ====================
# Mock Mode
# ====================

# Use mock responses instead of real API calls (for testing)
USE_MOCK_MODE=False

# ====================
# Rate Limiting
# ====================

# Requests per minute (to avoid hitting API limits)
OPENAI_RPM=20
ANTHROPIC_RPM=50

# Delay between requests (seconds)
REQUEST_DELAY=0.5
