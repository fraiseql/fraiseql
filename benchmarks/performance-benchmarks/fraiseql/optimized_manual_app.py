"""Optimized manual benchmark for FraiseQL with Redis caching and projection tables."""

import json
import os
import time
from statistics import mean, quantiles

import asyncpg
import redis.asyncio as redis
from fastapi import FastAPI

app = FastAPI(title="Optimized FraiseQL Benchmark API")

# Database configuration
DATABASE_URL = os.environ.get(
    "DATABASE_URL", "postgresql://benchmark:benchmark@postgres-bench/benchmark_db"
)

# Redis connection
redis_client: redis.Redis = None


async def get_redis():
    """Get Redis client."""
    global redis_client
    if redis_client is None:
        try:
            redis_client = redis.Redis(
                host=os.environ.get("REDIS_HOST", "localhost"),
                port=int(os.environ.get("REDIS_PORT", "6379")),
                decode_responses=True,
            )
        except Exception as e:
            print(f"Redis connection failed: {e}")
            redis_client = None
    return redis_client


@app.on_event("startup")
async def startup_event():
    """Initialize optimizations on startup."""
    print("ðŸš€ Starting optimized FraiseQL manual benchmark app...")

    # Test Redis connection
    redis_conn = await get_redis()
    if redis_conn:
        try:
            await redis_conn.ping()
            print("âœ… Redis connection established")
        except Exception as e:
            print(f"âš ï¸  Redis connection failed: {e} - continuing without cache")
    else:
        print("âš ï¸  Redis not available - continuing without cache")

    print("ðŸ† Optimizations ready: Redis Caching + Projection Tables (tv_)")


@app.on_event("shutdown")
async def shutdown_event():
    """Clean up on shutdown."""
    global redis_client
    if redis_client:
        await redis_client.close()
    print("ðŸ›‘ Optimized benchmark app shutdown complete")


@app.get("/health")
async def health():
    """Health check with optimization status."""
    redis_status = "disconnected"
    redis_conn = await get_redis()
    if redis_conn:
        try:
            await redis_conn.ping()
            redis_status = "connected"
        except Exception:
            pass

    return {
        "status": "healthy",
        "redis": redis_status,
        "optimizations": ["projection_tables_tv", "redis_caching"],
        "database": "tv_users, tv_products, tv_orders projection tables enabled",
    }


@app.get("/benchmark/users")
async def benchmark_users(limit: int = 100):
    """Optimized user benchmarking using projection tables and Redis cache."""
    start_time = time.time()

    # Generate cache key
    cache_key = f"bench_users:{limit}"

    # Try Redis cache first
    redis_conn = await get_redis()
    if redis_conn:
        try:
            cached_result = await redis_conn.get(cache_key)
            if cached_result:
                cache_time = time.time() - start_time
                cached_data = json.loads(cached_result)
                return {
                    "query": "users",
                    "limit": limit,
                    "cached": True,
                    "cache_time_ms": cache_time * 1000,
                    "result_count": cached_data["result_count"],
                    "mean_ms": cached_data["mean_ms"],
                    "optimization": "redis_cache_hit",
                }
        except Exception as e:
            print(f"Redis cache read error: {e}")

    # Database query using projection table
    conn = await asyncpg.connect(DATABASE_URL)

    try:
        # Warm up using projection table
        await conn.fetch("SELECT data FROM tv_users LIMIT $1", limit)

        # Run benchmark with projection table (tv_users)
        times = []
        for _ in range(10):
            query_start = time.time()
            await conn.fetch("SELECT data FROM tv_users LIMIT $1", limit)
            times.append((time.time() - query_start) * 1000)  # Convert to ms

        result = {
            "query": "users",
            "limit": limit,
            "cached": False,
            "mean_ms": mean(times),
            "p95_ms": quantiles(times, n=20)[18] if len(times) >= 20 else max(times),
            "min_ms": min(times),
            "max_ms": max(times),
            "result_count": limit,
            "optimization": "projection_table_tv_users",
        }

        # Cache the result
        if redis_conn:
            try:
                await redis_conn.setex(
                    cache_key,
                    300,  # 5 minutes
                    json.dumps(result),
                )
            except Exception as e:
                print(f"Redis cache write error: {e}")

        total_time = time.time() - start_time
        result["total_time_ms"] = total_time * 1000

        print(f"ðŸš€ Optimized users query: {result['mean_ms']:.2f}ms avg (projection table)")
        return result

    finally:
        await conn.close()


@app.get("/benchmark/products")
async def benchmark_products(limit: int = 100):
    """Optimized product benchmarking using projection tables and Redis cache."""
    start_time = time.time()

    # Generate cache key
    cache_key = f"bench_products:{limit}"

    # Try Redis cache first
    redis_conn = await get_redis()
    if redis_conn:
        try:
            cached_result = await redis_conn.get(cache_key)
            if cached_result:
                cache_time = time.time() - start_time
                cached_data = json.loads(cached_result)
                return {
                    "query": "products",
                    "limit": limit,
                    "cached": True,
                    "cache_time_ms": cache_time * 1000,
                    "result_count": cached_data["result_count"],
                    "mean_ms": cached_data["mean_ms"],
                    "optimization": "redis_cache_hit",
                }
        except Exception as e:
            print(f"Redis cache read error: {e}")

    # Database query using projection table
    conn = await asyncpg.connect(DATABASE_URL)

    try:
        # Warm up using projection table
        await conn.fetch("SELECT data FROM tv_products LIMIT $1", limit)

        # Run benchmark with projection table (tv_products)
        times = []
        for _ in range(10):
            query_start = time.time()
            await conn.fetch("SELECT data FROM tv_products LIMIT $1", limit)
            times.append((time.time() - query_start) * 1000)  # Convert to ms

        result = {
            "query": "products",
            "limit": limit,
            "cached": False,
            "mean_ms": mean(times),
            "p95_ms": quantiles(times, n=20)[18] if len(times) >= 20 else max(times),
            "min_ms": min(times),
            "max_ms": max(times),
            "result_count": limit,
            "optimization": "projection_table_tv_products",
        }

        # Cache the result
        if redis_conn:
            try:
                await redis_conn.setex(
                    cache_key,
                    300,  # 5 minutes
                    json.dumps(result),
                )
            except Exception as e:
                print(f"Redis cache write error: {e}")

        total_time = time.time() - start_time
        result["total_time_ms"] = total_time * 1000

        print(f"ðŸš€ Optimized products query: {result['mean_ms']:.2f}ms avg (projection table)")
        return result

    finally:
        await conn.close()


@app.get("/benchmark/orders")
async def benchmark_orders(limit: int = 100):
    """Optimized order benchmarking using projection tables and Redis cache."""
    start_time = time.time()

    # Generate cache key
    cache_key = f"bench_orders:{limit}"

    # Try Redis cache first
    redis_conn = await get_redis()
    if redis_conn:
        try:
            cached_result = await redis_conn.get(cache_key)
            if cached_result:
                cache_time = time.time() - start_time
                cached_data = json.loads(cached_result)
                return {
                    "query": "orders",
                    "limit": limit,
                    "cached": True,
                    "cache_time_ms": cache_time * 1000,
                    "result_count": cached_data["result_count"],
                    "mean_ms": cached_data["mean_ms"],
                    "optimization": "redis_cache_hit",
                }
        except Exception as e:
            print(f"Redis cache read error: {e}")

    # Database query using projection table
    conn = await asyncpg.connect(DATABASE_URL)

    try:
        # Warm up using projection table
        await conn.fetch("SELECT data FROM tv_orders LIMIT $1", limit)

        # Run benchmark with projection table (tv_orders)
        times = []
        for _ in range(10):
            query_start = time.time()
            await conn.fetch("SELECT data FROM tv_orders LIMIT $1", limit)
            times.append((time.time() - query_start) * 1000)  # Convert to ms

        result = {
            "query": "orders",
            "limit": limit,
            "cached": False,
            "mean_ms": mean(times),
            "p95_ms": quantiles(times, n=20)[18] if len(times) >= 20 else max(times),
            "min_ms": min(times),
            "max_ms": max(times),
            "result_count": limit,
            "optimization": "projection_table_tv_orders",
        }

        # Cache the result
        if redis_conn:
            try:
                await redis_conn.setex(
                    cache_key,
                    300,  # 5 minutes
                    json.dumps(result),
                )
            except Exception as e:
                print(f"Redis cache write error: {e}")

        total_time = time.time() - start_time
        result["total_time_ms"] = total_time * 1000

        print(f"ðŸš€ Optimized orders query: {result['mean_ms']:.2f}ms avg (projection table)")
        return result

    finally:
        await conn.close()


@app.get("/cache/stats")
async def get_cache_stats():
    """Get Redis cache performance statistics."""
    redis_conn = await get_redis()
    if not redis_conn:
        return {"error": "Redis not available"}

    try:
        info = await redis_conn.info("stats")
        return {
            "redis_connected": True,
            "keyspace_hits": info.get("keyspace_hits", 0),
            "keyspace_misses": info.get("keyspace_misses", 0),
            "total_commands_processed": info.get("total_commands_processed", 0),
            "hit_rate_percent": info.get("keyspace_hits", 0)
            / max(1, info.get("keyspace_hits", 0) + info.get("keyspace_misses", 0))
            * 100,
            "optimization": "redis_statistics",
        }
    except Exception as e:
        return {"error": f"Redis stats failed: {e}"}


@app.get("/optimization/compare")
async def compare_optimizations(limit: int = 100):
    """Compare old views vs new projection tables performance."""
    conn = await asyncpg.connect(DATABASE_URL)

    try:
        # Test old views (v_users)
        old_times = []
        for _ in range(5):
            start = time.time()
            await conn.fetch("SELECT data FROM v_users LIMIT $1", limit)
            old_times.append((time.time() - start) * 1000)

        # Test new projection tables (tv_users)
        new_times = []
        for _ in range(5):
            start = time.time()
            await conn.fetch("SELECT data FROM tv_users LIMIT $1", limit)
            new_times.append((time.time() - start) * 1000)

        old_avg = mean(old_times)
        new_avg = mean(new_times)
        improvement = ((old_avg - new_avg) / old_avg) * 100

        return {
            "limit": limit,
            "old_views_avg_ms": old_avg,
            "projection_tables_avg_ms": new_avg,
            "improvement_percent": improvement,
            "speedup_factor": old_avg / new_avg,
            "optimization": "projection_table_comparison",
        }

    finally:
        await conn.close()


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8000)  # noqa: S104
