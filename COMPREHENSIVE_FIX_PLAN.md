# Comprehensive Fix Plan: All Remaining Test Issues

**Date**: 2025-10-22
**Current Status**: 3,508 passing, 44 skipped, 0 failing
**Goal**: Fix all 44 skipped tests

---

## üìä Executive Summary

### Problem Categories

| Category | Count | Priority | Complexity | Est. Time |
|----------|-------|----------|------------|-----------|
| **Rust JSON Generation Bugs** | 5 | üî• CRITICAL | High | 3-5 days |
| **Blog Template Validation** | 10 | üü° MEDIUM | Low | 1-2 days |
| **Dual-Mode Repository (Obsolete)** | 17 | üü¢ LOW | None | Delete tests |
| **Rust JSON Parsing Validation** | 1 | üü° MEDIUM | Medium | 1 day |
| **Shellcheck Linting** | 1 | üü¢ LOW | Low | 1 hour |
| **Total** | **44** | - | - | **5-8 days** |

---

## üî• Phase 1: Rust JSON Generation Bugs (CRITICAL)

### Problem Statement

**5 skipped tests** in `test_dict_where_mixed_filters_bug.py` fail because the Rust pipeline generates malformed JSON when filtering with nested objects.

**Symptoms:**
- Missing closing braces in JSON output
- Malformed JSON structure
- Filters being ignored or incorrectly applied

**Root Cause:**
The Rust pipeline (`fraiseql-rs`) has a bug in how it generates GraphQL JSON responses when queries involve nested objects in WHERE filters.

**Example:**
```python
# Query with nested object filter
where_dict = {
    "machine": {"id": {"eq": machine_1_id}},  # Nested filter
    "is_current": {"eq": True}                 # Direct filter
}

# Current behavior: Malformed JSON output
# Expected: Valid JSON with both filters applied
```

---

### Phase 1.1: Reproduce and Diagnose (4-6 hours)

**Objective**: Understand exactly what's wrong with the Rust JSON generation

#### Steps:

1. **Temporarily remove skip decorators** to see actual failures:
   ```python
   # tests/integration/database/repository/test_dict_where_mixed_filters_bug.py
   # Comment out @pytest.mark.skip lines
   ```

2. **Run tests and capture raw output**:
   ```bash
   uv run pytest tests/integration/database/repository/test_dict_where_mixed_filters_bug.py::TestDictWhereMixedFiltersBug::test_dict_where_with_nested_filter_only -xvs > rust_json_bug.log 2>&1
   ```

3. **Analyze the malformed JSON**:
   - What's the actual output?
   - What's missing (braces, commas, fields)?
   - Is it consistent across all 5 tests?

4. **Identify the Rust code responsible**:
   ```bash
   # fraiseql-rs is a separate Rust crate
   # Check if it's a Python wrapper issue or Rust issue
   grep -r "RustResponseBytes" src/fraiseql/core/
   ```

5. **Check Rust pipeline version**:
   ```python
   # src/fraiseql/core/rust_transformer.py
   # Check version and changelog
   ```

#### Deliverables:
- [ ] Detailed bug report with:
  - Exact malformed JSON examples
  - Expected vs actual output
  - Rust pipeline version
  - Stack trace if available

---

### Phase 1.2: Fix Rust JSON Generation (1-2 days)

**Two possible scenarios:**

#### Scenario A: It's a Python wrapper issue

**If the bug is in Python code:**

File: `src/fraiseql/core/rust_pipeline.py`

```python
# Check how nested objects are passed to Rust
# Look for JSON generation/serialization bugs
```

**Fix approach:**
1. Trace where nested object filters are processed
2. Check JSON serialization of query results
3. Fix brace/quote escaping issues
4. Add unit tests for nested object responses

#### Scenario B: It's a Rust crate issue

**If the bug is in `fraiseql-rs`:**

This is more complex and requires:

1. **Check if there's an updated version**:
   ```bash
   pip show fraiseql-rs
   # Check PyPI for newer version
   ```

2. **If no update available**, need to:
   - Clone fraiseql-rs repository
   - Reproduce bug in Rust
   - Fix Rust code
   - Build and test locally
   - Submit PR to fraiseql-rs
   - Wait for release
   - Update dependency

**Temporary workaround** (if Rust fix takes too long):
- Add Python-side JSON validation and correction
- Parse malformed JSON and fix common issues
- Log warning when applying workaround

---

### Phase 1.3: Test and Validate (4-6 hours)

1. **Remove all skip decorators** from the 5 tests:
   ```python
   # tests/integration/database/repository/test_dict_where_mixed_filters_bug.py
   # Remove all @pytest.mark.skip decorators
   ```

2. **Run tests**:
   ```bash
   uv run pytest tests/integration/database/repository/test_dict_where_mixed_filters_bug.py -v
   ```

3. **Verify all 5 tests pass**:
   - test_dict_where_with_nested_filter_only
   - test_dict_where_with_direct_filter_only
   - test_dict_where_with_mixed_nested_and_direct_filters_BUG
   - test_dict_where_with_multiple_direct_filters_after_nested
   - test_dict_where_with_direct_filter_before_nested

4. **Add regression tests**:
   ```python
   def test_nested_object_json_generation_various_depths():
       """Test JSON generation with nested objects at various depths."""
       # 1 level deep
       # 2 levels deep
       # 3 levels deep
   ```

---

### Phase 1 Summary

**Timeline**: 2-3 days (Python fix) or 1-2 weeks (Rust fix + release)
**Tests Fixed**: 5
**Files Modified**:
- `src/fraiseql/core/rust_pipeline.py` (Python fix)
- Or `fraiseql-rs` crate (Rust fix)
- `tests/integration/database/repository/test_dict_where_mixed_filters_bug.py` (remove skips)

**Success Criteria**:
- [ ] All 5 dict_where tests pass
- [ ] JSON is well-formed
- [ ] Nested object filters work correctly
- [ ] Direct field filters work correctly
- [ ] Mixed filters work correctly

---

## üìù Phase 2: Blog Template Validation (MEDIUM PRIORITY)

### Problem Statement

**10 skipped tests** in blog_simple and blog_enterprise examples fail with:
```
Failed to setup blog_simple test database: Template validation failed for blog_simple_template
```

**Root Cause**: Template database creation/validation is failing

---

### Phase 2.1: Diagnose Template Issue (2-3 hours)

#### Steps:

1. **Find template fixture code**:
   ```bash
   grep -r "blog_simple_template" tests/fixtures/ tests/conftest.py
   grep -r "Template validation failed" tests/
   ```

2. **Check template configuration**:
   ```bash
   ls -la examples/blog_simple/db/
   cat examples/blog_simple/db/schema.sql  # or equivalent
   ```

3. **Manually try to create template**:
   ```bash
   # Connect to test database
   psql -d fraiseql_test

   # Try template creation manually
   CREATE DATABASE blog_simple_template TEMPLATE template0;
   ```

4. **Check if it's a permissions issue**:
   ```sql
   -- Check template database permissions
   SELECT datname, datistemplate, datallowconn
   FROM pg_database
   WHERE datname LIKE '%blog%';
   ```

5. **Check fixture code**:
   ```python
   # tests/fixtures/database/database_conftest.py or similar
   # Look for blog_simple_template fixture
   ```

#### Deliverables:
- [ ] Root cause identified (permissions, schema, or config)
- [ ] Error message captured
- [ ] Reproduction steps documented

---

### Phase 2.2: Fix Template Validation (3-5 hours)

**Common fixes:**

#### Fix 1: Missing Schema Files

If schema files are missing or incorrect:

```bash
# Check if schema exists
ls examples/blog_simple/db/*.sql

# If missing, create from models
python examples/blog_simple/generate_schema.py  # if exists
# or manually create schema
```

#### Fix 2: Template Database Already Exists

```python
# tests/fixtures/database/database_conftest.py

@pytest.fixture(scope="session")
async def blog_simple_template(db_pool):
    """Create blog_simple template database."""
    async with db_pool.connection() as conn:
        # Drop existing template if it exists
        await conn.execute("""
            DROP DATABASE IF EXISTS blog_simple_template;
        """)

        # Create new template
        await conn.execute("""
            CREATE DATABASE blog_simple_template
            TEMPLATE template0
            ENCODING 'UTF8';
        """)

        # Run schema setup
        # ... apply migrations ...
```

#### Fix 3: Validation Logic Too Strict

```python
# If validation is checking for specific tables/data
# Make validation more lenient or fix the schema
def validate_blog_template(db_name):
    # Check essential tables exist
    # Don't fail on missing optional data
```

---

### Phase 2.3: Test All Blog Examples (2-3 hours)

1. **Remove skip decorators**:
   ```python
   # tests/integration/examples/test_blog_simple_integration.py
   # tests/integration/examples/test_blog_enterprise_integration.py
   ```

2. **Run all blog tests**:
   ```bash
   uv run pytest tests/integration/examples/test_blog_simple_integration.py -v
   uv run pytest tests/integration/examples/test_blog_enterprise_integration.py -v
   ```

3. **Verify examples work end-to-end**:
   ```bash
   cd examples/blog_simple
   python app.py  # Should start without errors
   ```

---

### Phase 2 Summary

**Timeline**: 1-2 days
**Tests Fixed**: 10
**Files Modified**:
- `tests/fixtures/database/database_conftest.py` (or similar)
- `examples/blog_simple/db/` schemas (if needed)
- Test files (remove skips)

**Success Criteria**:
- [ ] Template database creates successfully
- [ ] All 10 blog example tests pass
- [ ] Blog examples can run standalone
- [ ] No template validation errors

---

## üóëÔ∏è Phase 3: Remove Obsolete Dual-Mode Tests (LOW PRIORITY)

### Problem Statement

**17 skipped tests** in `test_dual_mode_repository_unit.py` are obsolete because:
- "Mode detection logic removed from repository - now always uses Rust pipeline"
- "Test file has undefined types and import issues"

These tests are for the OLD dual-mode architecture that was removed in v1.0.

---

### Phase 3.1: Delete Obsolete Tests (1-2 hours)

**Objective**: Clean up codebase by removing obsolete tests

#### Steps:

1. **Verify tests are truly obsolete**:
   ```bash
   cat tests/integration/database/repository/test_dual_mode_repository_unit.py
   # Read skip reasons - all mention "Mode detection logic removed"
   ```

2. **Archive test file** (don't delete, keep for reference):
   ```bash
   mkdir -p archive/tests/obsolete_dual_mode/
   mv tests/integration/database/repository/test_dual_mode_repository_unit.py \
      archive/tests/obsolete_dual_mode/test_dual_mode_repository_unit.py.archive
   ```

3. **Add README** explaining why archived:
   ```markdown
   # archive/tests/obsolete_dual_mode/README.md

   ## Obsolete Dual-Mode Tests

   These tests were for the dual-mode architecture (Python/Rust) that was
   removed in FraiseQL v1.0 when we moved to Rust-first architecture.

   **Why removed:**
   - Mode detection logic no longer exists
   - Repository always uses Rust pipeline now
   - Tests have undefined types/imports

   **Date removed:** 2025-10-22
   **Version:** v0.11.6
   ```

4. **Update test count documentation**:
   ```bash
   # Update any docs that mention total test count
   # 3,508 + 17 = 3,525 tests after cleanup
   ```

---

### Phase 3 Summary

**Timeline**: 1-2 hours
**Tests "Fixed"**: 17 (removed)
**Files Removed**: 1
**Files Created**: 1 (README)

**Success Criteria**:
- [ ] Obsolete test file archived
- [ ] Test count updated in docs
- [ ] No references to dual-mode in active code
- [ ] Total skipped tests: 44 - 17 = 27

---

## üîç Phase 4: Rust JSON Parsing Validation (MEDIUM PRIORITY)

### Problem Statement

**1 skipped test** in `test_repository_where_integration.py`:
```python
@pytest.mark.skip(reason="Rust pipeline JSON parsing not yet working - skipping validation")
def test_rust_pipeline_returns_valid_json():
    ...
```

---

### Phase 4.1: Investigate JSON Parsing (2-3 hours)

#### Steps:

1. **Check what this test does**:
   ```bash
   cat tests/integration/database/repository/test_repository_where_integration.py
   # Look at test_rust_pipeline_returns_valid_json
   ```

2. **Understand the issue**:
   - Is this related to Phase 1 Rust bugs?
   - Or is it a separate validation issue?

3. **Try to run the test**:
   ```bash
   # Remove skip decorator temporarily
   uv run pytest tests/integration/database/repository/test_repository_where_integration.py::TestRepositoryWhereIntegration::test_rust_pipeline_returns_valid_json -xvs
   ```

4. **Analyze failure**:
   - What JSON is being returned?
   - What validation is failing?
   - Is it a schema issue or data issue?

---

### Phase 4.2: Fix JSON Parsing/Validation (3-5 hours)

**Possible fixes:**

#### Fix 1: Update Validation Logic

```python
def test_rust_pipeline_returns_valid_json(db_pool):
    """Test that Rust pipeline returns valid, parseable JSON."""
    repo = FraiseQLRepository(db_pool)

    result = await repo.find("some_view", where={...})

    # Parse JSON
    try:
        parsed = json.loads(bytes(result).decode("utf-8"))
        assert "data" in parsed
        assert isinstance(parsed["data"], (dict, list))
    except json.JSONDecodeError as e:
        pytest.fail(f"Rust pipeline returned invalid JSON: {e}")
```

#### Fix 2: Fix Rust Output Format

If the Rust pipeline is returning non-standard JSON:

```python
# src/fraiseql/core/rust_pipeline.py

def parse_rust_response(rust_bytes):
    """Parse RustResponseBytes to validated JSON."""
    raw = bytes(rust_bytes).decode("utf-8")

    # Fix common issues
    raw = fix_rust_json_issues(raw)

    return json.loads(raw)
```

---

### Phase 4 Summary

**Timeline**: 1 day
**Tests Fixed**: 1
**Files Modified**:
- `tests/integration/database/repository/test_repository_where_integration.py`
- Possibly `src/fraiseql/core/rust_pipeline.py`

**Success Criteria**:
- [ ] Test passes
- [ ] JSON validation is comprehensive
- [ ] Rust JSON output is validated

---

## üõ†Ô∏è Phase 5: Shellcheck Linting (LOW PRIORITY)

### Problem Statement

**1 skipped test** in `test_import_script.py`:
```python
@pytest.mark.skip(reason="shellcheck not installed")
def test_script_passes_shellcheck():
    ...
```

---

### Phase 5.1: Install Shellcheck (5 minutes)

```bash
# Ubuntu/Debian
sudo apt-get install shellcheck

# macOS
brew install shellcheck

# Verify
shellcheck --version
```

---

### Phase 5.2: Fix Shell Script Issues (1-2 hours)

1. **Remove skip decorator**:
   ```python
   # tests/grafana/test_import_script.py
   # Remove skip decorator
   ```

2. **Run test to see what fails**:
   ```bash
   uv run pytest tests/grafana/test_import_script.py::TestImportScriptLinting::test_script_passes_shellcheck -xvs
   ```

3. **Fix shellcheck warnings**:
   ```bash
   # Run shellcheck manually on the script
   shellcheck path/to/import_script.sh

   # Fix common issues:
   # - Quote variables: "$var" not $var
   # - Use [[ ]] for conditions
   # - Check exit codes
   # - Avoid useless cat
   ```

4. **Re-run test**:
   ```bash
   uv run pytest tests/grafana/test_import_script.py -v
   ```

---

### Phase 5 Summary

**Timeline**: 1-2 hours (if script needs fixes)
**Tests Fixed**: 1
**Files Modified**:
- Shell script being tested
- Test file (remove skip)

**Success Criteria**:
- [ ] Shellcheck installed
- [ ] Script passes shellcheck
- [ ] Test passes

---

## üìä Overall Implementation Strategy

### Recommended Order

```
Priority 1: Phase 1 (Rust JSON bugs) - MUST FIX
  ‚îú‚îÄ Blocks nested object functionality
  ‚îú‚îÄ Critical for production use
  ‚îî‚îÄ Affects 5 tests

Priority 2: Phase 3 (Remove obsolete) - QUICK WIN
  ‚îú‚îÄ Takes 1-2 hours
  ‚îú‚îÄ Reduces noise
  ‚îî‚îÄ Cleans up 17 tests

Priority 3: Phase 2 (Blog templates) - MEDIUM
  ‚îú‚îÄ Affects examples/documentation
  ‚îú‚îÄ Not blocking core functionality
  ‚îî‚îÄ Affects 10 tests

Priority 4: Phase 4 (JSON validation) - MEDIUM
  ‚îú‚îÄ May be fixed by Phase 1
  ‚îú‚îÄ Single test
  ‚îî‚îÄ Validation/QA issue

Priority 5: Phase 5 (Shellcheck) - LOW
  ‚îú‚îÄ Dev tooling only
  ‚îú‚îÄ Single test
  ‚îî‚îÄ Easy fix
```

---

## üéØ Execution Plan

### Week 1: Critical Bugs
- **Days 1-3**: Phase 1 (Rust JSON generation bugs)
- **Day 3**: Phase 3 (Remove obsolete tests) - quick win
- **End of week**: -22 skipped tests (5 fixed + 17 removed)

### Week 2: Polish
- **Days 1-2**: Phase 2 (Blog templates)
- **Day 3**: Phase 4 (JSON validation)
- **Day 3**: Phase 5 (Shellcheck)
- **End of week**: All tests passing! 0 skipped

---

## üìà Progress Tracking

### Current State
- ‚úÖ 3,508 tests passing
- ‚ö†Ô∏è 44 tests skipped
- ‚ùå 0 tests failing

### After Phase 1
- ‚úÖ 3,513 tests passing (+5)
- ‚ö†Ô∏è 39 tests skipped (-5)
- ‚ùå 0 tests failing

### After Phase 3
- ‚úÖ 3,513 tests passing
- ‚ö†Ô∏è 22 tests skipped (-17 removed)
- ‚ùå 0 tests failing

### After Phase 2
- ‚úÖ 3,523 tests passing (+10)
- ‚ö†Ô∏è 12 tests skipped (-10)
- ‚ùå 0 tests failing

### After Phase 4 & 5
- ‚úÖ 3,525 tests passing (+2)
- ‚ö†Ô∏è 0 tests skipped (-12) **üéâ ALL TESTS PASSING!**
- ‚ùå 0 tests failing

---

## üöß Risk Assessment

### High Risk
- **Phase 1**: Requires Rust fix - may need to wait for upstream release
  - **Mitigation**: Implement Python workaround for JSON fixing
  - **Fallback**: Keep tests skipped but document the bug

### Medium Risk
- **Phase 2**: Template creation might have deep issues
  - **Mitigation**: Manual database inspection first
  - **Fallback**: Simplify template to minimum viable schema

### Low Risk
- **Phases 3, 4, 5**: Straightforward fixes

---

## üìù Success Criteria

### Overall Goals
- [ ] 0 skipped tests (or all skips are documented/justified)
- [ ] 0 failing tests
- [ ] 3,525+ tests passing
- [ ] All core functionality working
- [ ] All examples working
- [ ] Clean test suite

### Quality Gates
- [ ] All tests have clear purpose
- [ ] No obsolete tests remain
- [ ] Test coverage maintained or improved
- [ ] CI/CD pipeline green
- [ ] Documentation updated

---

## üéâ Final Deliverables

1. **All Tests Passing**
   - Comprehensive test suite
   - No skipped tests
   - All features validated

2. **Clean Codebase**
   - Obsolete tests removed
   - Documentation updated
   - Examples working

3. **Bug Fixes**
   - Rust JSON generation fixed
   - Template validation working
   - All edge cases covered

4. **Documentation**
   - Test fix documentation
   - Migration notes if needed
   - Updated test count in README

---

## üîç Next Steps After This Plan

Once all tests are passing:

1. **Performance Testing**
   - Benchmark critical paths
   - Profile slow tests
   - Optimize hot paths

2. **Integration Testing**
   - End-to-end scenarios
   - Real-world use cases
   - Load testing

3. **Release v0.11.6**
   - All features complete
   - All tests passing
   - Ready for production

---

**Estimated Total Time**: 5-8 days
**Estimated Calendar Time**: 2 weeks (with buffer)
**Priority**: CRITICAL (Phase 1) to LOW (Phase 5)
**Complexity**: HIGH (Phase 1) to LOW (Phase 5)

---

*Generated: 2025-10-22*
*Next Review: After Phase 1 completion*
